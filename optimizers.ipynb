{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/impanaj07/deep_learning/blob/main/optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMq7M1i-21cc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3_fmh7C4s2J"
      },
      "outputs": [],
      "source": [
        "def load_mnist():\n",
        "  mnist=keras.datasets.mnist\n",
        "  (X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
        "  X_train=X_train.reshape(X_train.shape[0],28,28,1).astype('float32')/255\n",
        "  X_test=X_test.reshape(X_test.shape[0],28,28,1).astype('float32')/255\n",
        "  y_train=to_categorical(y_train,10)\n",
        "  y_test=to_categorical(y_test,10)\n",
        "  return X_train,X_test,y_train,y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD0YY93X7JPW"
      },
      "outputs": [],
      "source": [
        "def build_model(optimizer):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # First Convolutional Layer\n",
        "    model.add(layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1)))\n",
        "    model.add(layers.BatchNormalization())  # Batch Normalization\n",
        "    model.add(layers.Activation('relu'))    # ReLU Activation\n",
        "    model.add(layers.Dropout(0.3))          # Dropout Layer\n",
        "\n",
        "    # Second Convolutional Layer\n",
        "    model.add(layers.Conv2D(32, (3, 3)))\n",
        "    model.add(layers.BatchNormalization())  # Batch Normalization\n",
        "    model.add(layers.Activation('relu'))    # ReLU Activation\n",
        "    model.add(layers.Dropout(0.3))          # Dropout Layer\n",
        "\n",
        "    # Third Convolutional Layer\n",
        "    model.add(layers.Conv2D(16, (3, 3)))\n",
        "    model.add(layers.BatchNormalization())  # Batch Normalization\n",
        "    model.add(layers.Activation('relu'))    # ReLU Activation\n",
        "    model.add(layers.Dropout(0.3))          # Dropout Layer\n",
        "\n",
        "    model.add(layers.MaxPooling2D((2, 2)))  # Max Pooling Layer\n",
        "    model.add(layers.Flatten())              # Flatten the output\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(layers.Dense(15, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))           # Dropout Layer\n",
        "    model.add(layers.Dense(25, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))           # Dropout Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))  # Output Layer\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwy9YpaI71iP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9CobT1m9Mqn",
        "outputId": "3f0b1f57-eb21-412f-89d0-f56f61d95d6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 321ms/step - accuracy: 0.1122 - loss: 2.3139 - val_accuracy: 0.1102 - val_loss: 2.3014\n",
            "Epoch 2/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 316ms/step - accuracy: 0.1115 - loss: 2.3013 - val_accuracy: 0.1102 - val_loss: 2.3015\n",
            "Epoch 3/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 303ms/step - accuracy: 0.1145 - loss: 2.3008 - val_accuracy: 0.1102 - val_loss: 2.3015\n",
            "Epoch 1/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 312ms/step - accuracy: 0.1963 - loss: 2.1319 - val_accuracy: 0.6223 - val_loss: 1.2292\n",
            "Epoch 2/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 310ms/step - accuracy: 0.3896 - loss: 1.6251 - val_accuracy: 0.7003 - val_loss: 0.9845\n",
            "Epoch 3/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 308ms/step - accuracy: 0.4281 - loss: 1.5219 - val_accuracy: 0.7619 - val_loss: 0.8502\n",
            "Epoch 1/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 308ms/step - accuracy: 0.1536 - loss: 2.2342 - val_accuracy: 0.5667 - val_loss: 1.5618\n",
            "Epoch 2/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 309ms/step - accuracy: 0.3242 - loss: 1.8587 - val_accuracy: 0.6786 - val_loss: 1.1808\n",
            "Epoch 3/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 310ms/step - accuracy: 0.3694 - loss: 1.7190 - val_accuracy: 0.6827 - val_loss: 1.0740\n",
            "Epoch 1/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 304ms/step - accuracy: 0.1191 - loss: 2.3488 - val_accuracy: 0.2827 - val_loss: 2.1718\n",
            "Epoch 2/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 304ms/step - accuracy: 0.1753 - loss: 2.1921 - val_accuracy: 0.3246 - val_loss: 2.0479\n",
            "Epoch 3/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 305ms/step - accuracy: 0.2019 - loss: 2.1252 - val_accuracy: 0.3947 - val_loss: 1.9898\n",
            "Epoch 1/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 302ms/step - accuracy: 0.1081 - loss: 2.9987 - val_accuracy: 0.1494 - val_loss: 2.2978\n",
            "Epoch 2/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 310ms/step - accuracy: 0.1093 - loss: 2.4916 - val_accuracy: 0.1457 - val_loss: 2.2965\n",
            "Epoch 3/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 312ms/step - accuracy: 0.1145 - loss: 2.3700 - val_accuracy: 0.1462 - val_loss: 2.2968\n",
            "Epoch 1/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 323ms/step - accuracy: 0.2058 - loss: 2.1041 - val_accuracy: 0.3921 - val_loss: 1.6858\n",
            "Epoch 2/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 341ms/step - accuracy: 0.2456 - loss: 1.9402 - val_accuracy: 0.3313 - val_loss: 1.6267\n",
            "Epoch 3/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 328ms/step - accuracy: 0.2659 - loss: 1.9149 - val_accuracy: 0.3301 - val_loss: 1.6153\n",
            "Epoch 1/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 321ms/step - accuracy: 0.1112 - loss: 2.2767 - val_accuracy: 0.3012 - val_loss: 1.9336\n",
            "Epoch 2/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 316ms/step - accuracy: 0.2262 - loss: 2.0404 - val_accuracy: 0.3113 - val_loss: 1.8240\n",
            "Epoch 3/3\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 298ms/step - accuracy: 0.2532 - loss: 1.9359 - val_accuracy: 0.3136 - val_loss: 1.7652\n",
            "Optimizer: adam, Validation Accuracy: 0.1102, Test Accuracy: 0.1135\n",
            "Optimizer: rmsprop, Validation Accuracy: 0.7619, Test Accuracy: 0.7663\n",
            "Optimizer: sgd, Validation Accuracy: 0.6827, Test Accuracy: 0.6880\n",
            "Optimizer: adagrad, Validation Accuracy: 0.3947, Test Accuracy: 0.3913\n",
            "Optimizer: adadelta, Validation Accuracy: 0.1462, Test Accuracy: 0.1466\n",
            "Optimizer: nadam, Validation Accuracy: 0.3301, Test Accuracy: 0.3299\n",
            "Optimizer: adamax, Validation Accuracy: 0.3136, Test Accuracy: 0.3142\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "X_train, X_test, y_train, y_test = load_mnist()\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Test different optimizers\n",
        "optimizers = ['adam', 'rmsprop', 'sgd', 'adagrad', 'adadelta', 'nadam', 'adamax']\n",
        "results = {}\n",
        "\n",
        "for opt in optimizers:\n",
        "    model = build_model(opt)\n",
        "    history = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # Get validation accuracy\n",
        "    val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "    # Evaluate test accuracy\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    results[opt] = {\n",
        "        'validation_accuracy': val_accuracy,\n",
        "        'test_accuracy': test_acc\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "for opt, acc in results.items():\n",
        "    print(f\"Optimizer: {opt}, Validation Accuracy: {acc['validation_accuracy']:.4f}, Test Accuracy: {acc['test_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtGgY8yh9ewf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLjH6qaQoTdNIWbpym/XGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}