{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNIiukLaE7WueP7we2dIJKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/impanaj07/deep_learning/blob/main/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "alIvL5ufw8NR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmWD8Qle4Be6",
        "outputId": "cfd2bec3-be99-4f14-b429-81d66b7cc119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 30ms/step - accuracy: 0.1058 - loss: 2.3946 - val_accuracy: 0.0991 - val_loss: 2.3026\n",
            "Epoch 2/5\n",
            "\u001b[1m   1/1562\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.0625 - loss: 2.3025"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 2.3025 - val_accuracy: 0.0981 - val_loss: 2.3026\n",
            "Epoch 3/5\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 25ms/step - accuracy: 0.1020 - loss: 2.3028 - val_accuracy: 0.1004 - val_loss: 2.3027\n",
            "Epoch 4/5\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0625 - loss: 2.3079 - val_accuracy: 0.1004 - val_loss: 2.3027\n",
            "Epoch 5/5\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.0983 - loss: 2.3027 - val_accuracy: 0.1000 - val_loss: 2.3026\n",
            "Epoch 1/2\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 39ms/step - accuracy: 0.1765 - loss: 2.3790 - val_accuracy: 0.1441 - val_loss: 2.3342\n",
            "Epoch 2/2\n",
            "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3125 - loss: 2.0645 - val_accuracy: 0.1437 - val_loss: 2.3282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# Define parameters\n",
        "img_size = (32, 32)  # CIFAR-10 image size\n",
        "batch_size = 32\n",
        "num_classes = 10  # CIFAR-10 has 10 classes\n",
        "epochs =  5 # Adjust as needed\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train_raw), (x_val, y_val_raw) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train_raw, num_classes=num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val_raw, num_classes=num_classes)\n",
        "\n",
        "# Data Augmentation and Preprocessing\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    # validation_split is not used here as we have a separate validation set\n",
        ")\n",
        "\n",
        "datagen_val = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = datagen_train.flow(\n",
        "    x_train, y_train,  # Use one-hot encoded labels here\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_generator = datagen_val.flow(\n",
        "    x_val, y_val,    # Use one-hot encoded labels here\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load Pretrained Model (ResNet50 does not have pre-trained weights for CIFAR-10)\n",
        "# We will use weights='imagenet' and fine-tune\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# Add Custom Layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "out = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Compile Model\n",
        "model = Model(inputs=base_model.input, outputs=out)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    validation_steps=len(x_val) // batch_size\n",
        ")\n",
        "\n",
        "# Fine-tune the model by unfreezing some layers\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:  # Keep some layers frozen\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile again with a lower learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train again for fine-tuning\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=epochs // 2,\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    validation_steps=len(x_val) // batch_size\n",
        ")\n",
        "\n",
        "# Save Model\n",
        "model.save(\"fine_tuned_resnet50_cifar10.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSaVeyRX4G3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NDzF29yy4gNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zHbruAs4k2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}